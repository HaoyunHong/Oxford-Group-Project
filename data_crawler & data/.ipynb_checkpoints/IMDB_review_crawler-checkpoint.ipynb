{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review crawler\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.request\n",
    "from lxml.html import fromstring\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# download html\n",
    "def download(url):\n",
    "    print('Downloading:', url)\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header('User-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36')\n",
    "    resp = urllib.request.urlopen(request)\n",
    "    html = resp.read().decode('utf-8')\n",
    "    return html\n",
    "\n",
    "\n",
    "def generate_movie_review_list_link():\n",
    "    start_url = download('https://www.imdb.com/chart/top/?ref_=nv_mv_250')\n",
    "    domain = 'https://www.imdb.com/'\n",
    "    start_soup = BeautifulSoup(start_url)\n",
    "    \n",
    "    movie_reviews_url_list = []\n",
    "    \n",
    "    for k in range(250):\n",
    "        sub_html = start_soup.find_all('tbody')[0].find_all('a')[2*k+1].get('href')\n",
    "        url = domain + sub_html\n",
    "        # print(\"url: \", url)\n",
    "        id_pattern = re.compile(r'(?<=tt)\\d+(?=/?)')\n",
    "        movie_id = str(id_pattern.search(url).group()).zfill(7)    #imdb电影id\n",
    "        print(\"movie_id: \", movie_id)\n",
    "        movie_reviews_url = \"https://www.imdb.com/title/tt\"+str(movie_id)+\"/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\"\n",
    "        # print(\"movie_reviews_url: \", movie_reviews_url)\n",
    "        movie_reviews_url_list.append([movie_id,movie_reviews_url])\n",
    "\n",
    "    return movie_reviews_url_list\n",
    "\n",
    "#获取imdb电影评论页面所有非spoiler的用户评论\n",
    "def get_imdb_movie_review(url,movieId):\n",
    "    NETWORK_STATUS = True  # 判断状态变量\n",
    "    URL = url\n",
    "    print(URL)\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        if response.status_code == 200:\n",
    "            original_html = response.text\n",
    "            original_soup = BeautifulSoup(original_html,'lxml')\n",
    "            #需要下载Chromedriver\n",
    "            driver = webdriver.Chrome()\n",
    "            driver.get(URL)\n",
    "\n",
    "            # 判断是否需要模拟点击load more 按钮\n",
    "            i=0\n",
    "            while(i<5):\n",
    "                i+=1\n",
    "                temp_response = driver.page_source\n",
    "                temp_html = temp_response\n",
    "                temp_soup = BeautifulSoup(temp_html,'lxml')\n",
    "                load_more = temp_soup.select('.ipl-load-more__button')\n",
    "                #需要模拟点击\n",
    "                if(len(load_more) == 1):\n",
    "                    button_load_more = driver.find_element_by_class_name('ipl-load-more__button')\n",
    "                    button_is_or_not_visible = driver.find_element_by_class_name('ipl-load-more__button').is_displayed()\n",
    "                    if(button_is_or_not_visible is True and i<5):       #button按钮不可见时停止点击\n",
    "                        button_load_more.click()\n",
    "                        time.sleep(3)\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            final_response = driver.page_source\n",
    "            html = final_response\n",
    "            soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "            movie_id = movieId\n",
    "            reviews = soup.select('.review-container')\n",
    "            movie_reviews_list = [[0] * 4 for j in range(200)]\n",
    "\n",
    "            i = 0\n",
    "            for review in reviews:\n",
    "                header = review.select_one('.display-name-date')\n",
    "                user_link = header.select_one('a')['href']\n",
    "                user_id_pattern = re.compile(r'(?<=ur)\\d+(?=/?)')\n",
    "                user_id = int(user_id_pattern.search(user_link).group())    #用户id\n",
    "                review_date = header.select_one('.review-date').string      #用户评论时间\n",
    "\n",
    "                content = review.select_one('.content')\n",
    "                user_review = content.select('.text.show-more__control')     #用户评论\n",
    "                movie_reviews_list[i][0] = movie_id\n",
    "                movie_reviews_list[i][1] = review_date\n",
    "                movie_reviews_list[i][2] = user_id\n",
    "                movie_reviews_list[i][3] = user_review\n",
    "\n",
    "                i += 1\n",
    "                #print(i,user_id,review_date,user_review,movie_id)\n",
    "                time.sleep(0.01)\n",
    "                if i>= 100:\n",
    "                    break\n",
    "\n",
    "            driver.close()      #关闭网页\n",
    "            return movie_reviews_list\n",
    "        else:\n",
    "            print(\"Error when request URL\")\n",
    "    except RequestException:\n",
    "        print(\"Request Failed\")\n",
    "        return None\n",
    "    except requests.exceptions.Timeout:\n",
    "        NETWORK_STATUS = False  # 请求超时改变状态\n",
    "        if NETWORK_STATUS == False:\n",
    "            #'''请求超时'''\n",
    "            driver.close()  # 关闭网页\n",
    "            print('请求超时，重复请求')\n",
    "            get_imdb_movie_review(URL, movieId)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    count = 0\n",
    "    with open('imdb_movie_review_info.csv', 'w', newline=\"\",encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, dialect=(\"excel\"))\n",
    "        csvwriter.writerow([\"movieId\", \"reviewDate\", \"userId\", \"userReview\"])\n",
    "        movie_review_url_list =  generate_movie_review_list_link()\n",
    "        print(\"movie_review_url_list: \", movie_review_url_list)\n",
    "        j = 0\n",
    "\n",
    "        while (j < 250):\n",
    "            print(\"第\" + str(j + 1) + \"部电影的评论\")\n",
    "            # 只收集前100条 order by helpfulness\n",
    "            l = [[0] * 4 for j in range(200)]\n",
    "            l = get_imdb_movie_review(movie_review_url_list[j][1], movie_review_url_list[j][0])\n",
    "            k = 0\n",
    "            if(l is None):\n",
    "                j += 1\n",
    "                continue\n",
    "\n",
    "            while(l[k][2] != 0):\n",
    "                csvwriter.writerow(l[k])\n",
    "                k += 1\n",
    "                count += 1\n",
    "            j += 1\n",
    "\n",
    "    print(\"爬虫完毕，共爬取\"+str(count)+\"个用户评论\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
